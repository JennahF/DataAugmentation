2021-05-20 20:43:27,235 - train.py[line:68] - INFO: {'word_embedding_dimension': 300, 'Epoch1': 13, 'Epoch2': 10, 'dropout': 0.1, 'label_num': 2, 'learning_rate1': 0.0001, 'learning_rate2': 1e-05, 'batch_size': 128, 'cuda': True, 'negSampleNum': 12, 'poSampleNum': 1, 'max_bound': 1.0, 'kernel_sizes': [3, 4, 5], 'hidden_size': 256, 'hidden_layers': 1, 'bidirectional': True}
2021-05-20 20:43:27,235 - train.py[line:69] - INFO: Namespace(bs=128, dataset='CoLA', epoch=13, l2=1e-05, loadmodel=0, lr=0.0001, maxbound=1.0, modelfilename='110_Epoch_12_model_1_12_0.708.pt', modelname='TextCNN', modelnum='0', negNum=12, posNum=1, resultnum=116, runmode='train', seed=1, startepoch=0)
2021-05-20 20:43:27,633 - train.py[line:231] - INFO: train data loaded!
2021-05-20 20:43:30,607 - train.py[line:255] - INFO: ...start training...
2021-05-20 20:44:48,488 - train.py[line:168] - INFO: Epoch 0, 66 th batch, total loss: 87328.29, aver loss: 1303.41, aver neg loss:   0.08, aver pos loss:   0.03, test acc:   0.68;     78 s elapsed
2021-05-20 20:46:07,991 - train.py[line:168] - INFO: Epoch 1, 66 th batch, total loss: 71638.16, aver loss: 1069.23, aver neg loss:   0.18, aver pos loss:   0.05, test acc:   0.68;    157 s elapsed
2021-05-20 20:47:25,831 - train.py[line:168] - INFO: Epoch 2, 66 th batch, total loss: 62255.59, aver loss: 929.19, aver neg loss:   0.24, aver pos loss:   0.06, test acc:   0.67;    235 s elapsed
2021-05-20 20:48:41,642 - train.py[line:168] - INFO: Epoch 3, 66 th batch, total loss: 56684.66, aver loss: 846.04, aver neg loss:   0.29, aver pos loss:   0.07, test acc:   0.67;    311 s elapsed
2021-05-20 20:50:01,355 - train.py[line:168] - INFO: Epoch 4, 66 th batch, total loss: 52269.99, aver loss: 780.15, aver neg loss:   0.33, aver pos loss:   0.07, test acc:   0.66;    391 s elapsed
2021-05-20 20:51:20,433 - train.py[line:168] - INFO: Epoch 5, 66 th batch, total loss: 48509.44, aver loss: 724.02, aver neg loss:   0.37, aver pos loss:   0.08, test acc:   0.64;    470 s elapsed
2021-05-20 20:52:36,324 - train.py[line:168] - INFO: Epoch 6, 66 th batch, total loss: 45476.67, aver loss: 678.76, aver neg loss:   0.41, aver pos loss:   0.09, test acc:   0.64;    546 s elapsed
2021-05-20 20:53:49,869 - train.py[line:168] - INFO: Epoch 7, 66 th batch, total loss: 43161.86, aver loss: 644.21, aver neg loss:   0.44, aver pos loss:   0.09, test acc:   0.61;    619 s elapsed
2021-05-20 20:55:02,359 - train.py[line:168] - INFO: Epoch 8, 66 th batch, total loss: 41618.23, aver loss: 621.17, aver neg loss:   0.46, aver pos loss:   0.10, test acc:   0.61;    692 s elapsed
2021-05-20 20:56:13,587 - train.py[line:168] - INFO: Epoch 9, 66 th batch, total loss: 40326.10, aver loss: 601.88, aver neg loss:   0.48, aver pos loss:   0.10, test acc:   0.58;    763 s elapsed
2021-05-20 20:57:24,873 - train.py[line:168] - INFO: Epoch 10, 66 th batch, total loss: 39470.48, aver loss: 589.11, aver neg loss:   0.50, aver pos loss:   0.11, test acc:   0.58;    834 s elapsed
2021-05-20 20:58:35,373 - train.py[line:168] - INFO: Epoch 11, 66 th batch, total loss: 38824.82, aver loss: 579.47, aver neg loss:   0.51, aver pos loss:   0.11, test acc:   0.59;    905 s elapsed
2021-05-20 20:59:51,171 - train.py[line:168] - INFO: Epoch 12, 66 th batch, total loss: 38207.50, aver loss: 570.26, aver neg loss:   0.52, aver pos loss:   0.11, test acc:   0.57;    981 s elapsed
2021-05-20 20:59:51,191 - train.py[line:184] - INFO: model saved!
